{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this tutorial: https://towardsdatascience.com/an-implementation-guide-to-word2vec-using-numpy-and-google-sheets-13445eebd281"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"natural language processing and machine learning are fun and exciting\"\n",
    "corpus = np.array([[w.lower() for w in text.split()]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {\n",
    "    \"window_size\": 2,\n",
    "    \"n\": 10,\n",
    "    \"epochs\": 50,\n",
    "    \"eta\": 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define word2vec Model and Generate Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class word2vec():\n",
    "    \n",
    "    def __init__(self, settings):\n",
    "        self.n = settings[\"n\"]\n",
    "        self.eta = settings[\"eta\"]\n",
    "        self.epochs = settings[\"epochs\"]\n",
    "        self.window_size = settings[\"window_size\"]\n",
    "        self.vocab_size = 0\n",
    "        self.vocab = []\n",
    "        self.word2index = {}\n",
    "        self.index2word = {}\n",
    "    \n",
    "    def generate_training_data(self, corpus):\n",
    "        assert type(corpus) == np.ndarray\n",
    "        self.vocab = np.array(list(set(corpus.flatten())))\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        for i, wd in enumerate(self.vocab):\n",
    "            self.word2index[wd] = i\n",
    "            self.index2word[i] = wd\n",
    "        \n",
    "        training_data = []\n",
    "        \n",
    "        for sentence in corpus:\n",
    "            sentence_len = len(sentence)\n",
    "            for i, wd in enumerate(sentence):\n",
    "                target = self.word2one_hot(wd)\n",
    "                context = []\n",
    "                \n",
    "                for j in range(i - self.window_size, i + self.window_size + 1):\n",
    "                    if j >= 0 and j != i and j < sentence_len:\n",
    "                        context.append(self.word2one_hot(sentence[j]))\n",
    "                training_data.append([target, np.array(context)])\n",
    "        return np.array(training_data)\n",
    "                \n",
    "                \n",
    "            \n",
    "    \n",
    "    def word2one_hot(self, word):\n",
    "        one_hot = np.zeros(shape=(self.vocab_size,), dtype=np.int32)\n",
    "        one_hot[self.word2index[word]] = 1\n",
    "        return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([0, 0, 0, 0, 0, 1, 0, 0, 0]),\n",
       "       array([[0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0]])], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v = word2vec(settings)\n",
    "X_train = w2v.generate_training_data(corpus)\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
