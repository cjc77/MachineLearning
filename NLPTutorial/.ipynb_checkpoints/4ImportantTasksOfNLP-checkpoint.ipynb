{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>4 Important Tasks of NLP</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>4.1 Text Classification</h1>\n",
    "<p>Text classification is a classic NLP problem. Examples:\n",
    "<ul>\n",
    "    <li>Email Spam Identification</li>\n",
    "    <li>Topic Classification of News</li>\n",
    "    <li>Sentiment Classification and Organization of Web Pages</li>\n",
    "</ul>\n",
    "</p>\n",
    "<p>Text classification is defined as a technique to systematically classify a text object (document or sentence) into a fixed category. This is mostly helpful for filtering, organizing, and storing large amounts of data.</p>\n",
    "<p>A typical natural language classifier consists of two parts:\n",
    "<ul>\n",
    "    <li>Training</li>\n",
    "    <li>Prediction</li>\n",
    "</ul>\n",
    "Firstly, the text input is processed and features are created. The machine learning models then learn these features and predict against new text.\n",
    "</p>\n",
    "<img src=\"language-classifier.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Code Using a naive Bayes classifier with the text blob library (built on top of nltk)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class_A\n",
      "Class_B\n",
      "['Class_B', 'Class_A', 'Class_A', 'Class_B', 'Class_A', 'Class_B']\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier as NBC\n",
    "from textblob import TextBlob\n",
    "\n",
    "training_corpus = [\n",
    "                   ('I am exhausted from this work.', 'Class_B'),\n",
    "                   (\"I can't cooperate with this\", 'Class_B'),\n",
    "                   ('He is my worst enemy!', 'Class_B'),\n",
    "                   ('My management is poor.', 'Class_B'),\n",
    "                   ('I love this burger.', 'Class_A'),\n",
    "                   ('This is an brilliant place!', 'Class_A'),\n",
    "                   ('I feel very good about these dates.', 'Class_A'),\n",
    "                   ('This is my best work.', 'Class_A'),\n",
    "                   (\"What an awesome view\", 'Class_A'),\n",
    "                   ('I do not like this dish', 'Class_B')]\n",
    "test_corpus = [\n",
    "                (\"I am not feeling well today.\", 'Class_B'), \n",
    "                (\"I feel brilliant!\", 'Class_A'), \n",
    "                ('Gary is a friend of mine.', 'Class_A'), \n",
    "                (\"I can't believe I'm doing this.\", 'Class_B'), \n",
    "                ('The date was good.', 'Class_A'),\n",
    "                ('I do not enjoy my job', 'Class_B')]\n",
    "\n",
    "model = NBC(training_corpus)\n",
    "print(model.classify(\"Their codes are amazing.\"))\n",
    "\n",
    "print(model.classify(\"I don't like their computer.\"))\n",
    "\n",
    "test_results = [model.classify(tup[0]) for tup in test_corpus]\n",
    "print(test_results)\n",
    "print(model.accuracy(test_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Scikit Learn Pipeline Framework for Text Classification</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    Class_A       0.50      0.67      0.57         3\n",
      "    Class_B       0.50      0.33      0.40         3\n",
      "\n",
      "avg / total       0.50      0.50      0.49         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "\n",
    "# Prepare data for SVM model - using same training\n",
    "# corpus and test corpus from Naive Bayes example\n",
    "train_data = []\n",
    "train_labels = []\n",
    "for tup in training_corpus:\n",
    "    train_data.append(tup[0])\n",
    "    train_labels.append(tup[1])\n",
    "    \n",
    "test_data = []\n",
    "test_labels = []\n",
    "for tup in test_corpus:\n",
    "    test_data.append(tup[0])\n",
    "    test_labels.append(tup[1])\n",
    "    \n",
    "# Create feature vectors\n",
    "# df = document frequency\n",
    "vectorizer = TfidfVectorizer(min_df=4, max_df=0.9)\n",
    "\n",
    "# Train the feature vectors\n",
    "train_vectors = vectorizer.fit_transform(train_data)\n",
    "\n",
    "# Apply model on test data\n",
    "test_vectors = vectorizer.transform(test_data)\n",
    "\n",
    "# Perform classification with SVM, kernel=linear\n",
    "model = svm.SVC(kernel=\"linear\")\n",
    "model.fit(train_vectors, train_labels)\n",
    "prediction = model.predict(test_vectors)\n",
    "# prediction.tolist()\n",
    "\n",
    "print(classification_report(test_labels, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>4.2 Text Matching / Similarity</h1>\n",
    "<p>One of the important areas of NLP is the matching of text objects to find similarities. Important applications of text matching include:\n",
    "<ul>\n",
    "    <li>Automatic Spelling Correction</li>\n",
    "    <li>Data De-Duplication</li>\n",
    "    <li>Genome Analysis</li>\n",
    "</ul>\n",
    "</p>\n",
    "<h3>Some Text Matching Techniques:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>A. Levenshtein Distance</h3>\n",
    "<p>The Levenshtein distance between two strings is defined as the minimum number of edits needed to transform one string into the other with the following operations:\n",
    "<ul>\n",
    "    <li>Insertion</li>\n",
    "    <li>Deletion</li>\n",
    "    <li>Substitution of a Single Character</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def levenshtein(s1, s2):\n",
    "    if len(s1) > len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "    distances = range(len(s1) + 1)\n",
    "    for index2, char2 in enumerate(s2):\n",
    "        newDistances = [index2 + 1]\n",
    "        for index1, char1 in enumerate(s1):\n",
    "            if char1 == char2:\n",
    "                newDistances.append(distances[index1])\n",
    "            else:\n",
    "                newDistances.append(1 + min((distances[index1],\n",
    "                                            distances[index1 + 1],\n",
    "                                            newDistances[-1])))\n",
    "        distances = newDistances\n",
    "    return distances[-1]\n",
    "\n",
    "print(levenshtein(\"analyze\", \"analyse\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>B. Phonetic Matching</h3>\n",
    "<p>A phonetic matching algorithm takes a keyword as input (person's name, location name, etc.) and produces a character string that identifies a set of words that are (roughly) phonetically similar. It is useful for searching large text corpuses, correcting spelling errors and matching relevant names. Soundex and Metaphone are two main phonetic algorithms used for this purpose. Python's module Fuzzy is used to compute soundex strings for different words:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A53\n",
      "A53\n"
     ]
    }
   ],
   "source": [
    "import fuzzy\n",
    "\n",
    "soundex = fuzzy.Soundex(4)\n",
    "\n",
    "print(soundex(\"aunt\"))\n",
    "print(soundex(\"ant\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>C. Flexible String Matching</h3>\n",
    "<p>A complete text matching system includes different algorithms pipelined together to compute a variety of text variations. Regular expressions are helpful for this purpose as well. Another common techniques include:\n",
    "<ul>\n",
    "    <li>Exact String Matching</li>\n",
    "    <li>Lemmatized Matching</li>\n",
    "    <li>Compacted Matching (takes care of spaces, punctuations, slangs, etc.)</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>D. Cosing Similarity</h3>\n",
    "<p>When the text is represented in vector notation, a general cosine similarity can also be applied in order to measure vectorized similarity. The following code converts text to vectors (using term frequency) and applies cosine similarity to provide closeness among two texts:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6249999999999999\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def get_cosine(vec1, vec2):\n",
    "    common = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in common])\n",
    "    \n",
    "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "    \n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "def text_to_vector(text):\n",
    "    words = text.split()\n",
    "    return Counter(words)\n",
    "\n",
    "text1 = \"This is a write-up about natural language processing.\"\n",
    "text2 = \"The write up is about natural language processing.\"\n",
    "\n",
    "vector1 = text_to_vector(text1)\n",
    "vector2 = text_to_vector(text2)\n",
    "cosine = get_cosine(vector1, vector2)\n",
    "print(cosine)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>4.3 Coreference Resolution</h1>\n",
    "<p>Coreference Resolution is the process of finding relational links among the words (or phrases) within sentences.</p>\n",
    "<p>Example: \"Donald went to John's office to see the new table. He looked at it for a minute.\"</p>\n",
    "<p>Coreference resolution is used to determine that \"he\" is Donald and \"it\" is the table. Coreference resolution is used in:\n",
    "<ul>\n",
    "    <li>Document Summarization</li>\n",
    "    <li>Question Answering</li>\n",
    "    <li>Information Extraction</li>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>4.4 Other NLP Problems/Tasks</h1>\n",
    "<ul>\n",
    "    <li><strong>Text Summarization - </strong> Given a text article or paragraph, summarize it automatically to produce the most important and relevant sentences in order.</li>\n",
    "    <li><strong>Machine Translation - </strong> Automatically translate text from one human language to another by taking care of grammar, semantics and information about the real world, etc.</li>\n",
    "    <li><strong>Natural Language Generation and Understanding - </strong> Convert information from computer databases or semantic intents into readable human language. Converting chunks of text into more logical structures that are easier for computer programs to manipulate is called language understanding.</li>\n",
    "    <li><strong>Optical Character Recognition - </strong> Given an image representing printed text, determine the corresponding text.</li>\n",
    "    <li><strong>Document to Information - </strong> This involves parsing of textual data present in documents (websites, files, pdfs, and images) into analyzable and clean format.</li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
