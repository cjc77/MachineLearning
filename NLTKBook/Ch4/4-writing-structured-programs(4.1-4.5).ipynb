{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>4.1 Back to the Basics</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Shallow Copy</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: [[1, 2, 3, -7], [4, 5, 6], [7, 8, 9]]\n",
      "\n",
      "B: [[1, 2, 3, -7], [4, 5, 6], [7, 8, 9]]\n"
     ]
    }
   ],
   "source": [
    "i = [1, 2, 3]\n",
    "j = [4, 5, 6]\n",
    "k = [7, 8, 9]\n",
    "\n",
    "a = [i, j, k]\n",
    "# Copy the object references from a\n",
    "b = a[:]\n",
    "b[0].append(-7)\n",
    "\n",
    "print(\"A: {}\\n\\nB: {}\".format(a, b,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Deep Copy</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: [[1, 2, 3, -7], [4, 5, 6], [7, 8, 9]]\n",
      "\n",
      "B: [[1, 2, 3, -7], [4, 5, 6], [7, 8, 9]]\n",
      "\n",
      "C: [[1, 2, 3, -7, -999], [4, 5, 6], [7, 8, 9]]\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy as dc\n",
    "\n",
    "c = dc(a)\n",
    "c[0].append(-999)\n",
    "print(\"A: {}\\n\\nB: {}\\n\\nC: {}\".format(a, b, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Equality</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Python'], ['Python'], ['Python'], ['Python'], ['Python']]\n",
      "KITTY CAT\n",
      "PUPPY DOG\n",
      "4412257992\n",
      "4412257992\n",
      "4412257992\n",
      "4412257992\n",
      "4412257992\n",
      "\n",
      "\n",
      "round 2\n",
      "[['Python'], ['Python'], ['Python'], ['Python'], ['Python']]\n",
      "KITTY CAT\n",
      "4412257992\n",
      "4412257992\n",
      "4412087240\n",
      "4412257992\n",
      "4412257992\n"
     ]
    }
   ],
   "source": [
    "size = 5\n",
    "python = [\"Python\"]\n",
    "snake_nest = [python] * size\n",
    "\n",
    "def test(nest):\n",
    "    print(nest)\n",
    "    # ==: same values\n",
    "    if nest[0] == nest[1] == nest[2] == nest[3] == nest[4]:\n",
    "        print(\"KITTY CAT\")\n",
    "    # is: same identity\n",
    "    if nest[0] is nest[1] is nest[2] is nest[3] is nest[4]:\n",
    "        print(\"PUPPY DOG\")\n",
    "\n",
    "def check_ids(nest):\n",
    "    for snake in nest:\n",
    "        print(id(snake))\n",
    "            \n",
    "test(snake_nest)\n",
    "check_ids(snake_nest)\n",
    "\n",
    "print(\"\\n\\nround 2\")\n",
    "import random\n",
    "pos = random.choice(range(size))\n",
    "snake_nest[pos] = [\"Python\"]\n",
    "\n",
    "test(snake_nest)\n",
    "check_ids(snake_nest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "sent = ['No', 'good', 'fish', 'goes', 'anywhere', 'without', 'a', 'porpoise', '.']\n",
    "print(all(len(w) > 4 for w in sent))\n",
    "\n",
    "print(any(len(w) > 4 for w in sent))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>4.2 Sequences</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('David', 234, ['Chocolate', 'Racecars'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faves = [\"Chocolate\", \"Racecars\"]\n",
    "tup = \"David\", 234, faves\n",
    "tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', '.', 'Red', 'lorry', 'red', 'yellow']\n",
      "Red: 1;  lorry: 4;  ,: 3;  yellow: 2;  red: 1;  .: 1;  "
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "raw = 'Red lorry, yellow lorry, red lorry, yellow lorry.'\n",
    "text = word_tokenize(raw)\n",
    "fdist = nltk.FreqDist(text)\n",
    "print(sorted(fdist))\n",
    "for key in fdist:\n",
    "    print(\"{}: {}; \".format(key, fdist[key]), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'turned', 'the', 'spectroroute', 'off']\n"
     ]
    }
   ],
   "source": [
    "words = ['I', 'turned', 'off', 'the', 'spectroroute']\n",
    "words[2], words[3], words[4] = words[3], words[4], words[2]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zip object at 0x10b67f648>\n",
      "[('I', 'noun'), ('turned', 'verb'), ('off', 'prep'), ('the', 'det'), ('spectroroute', 'noun')]\n",
      "[(0, 'I'), (1, 'turned'), (2, 'off'), (3, 'the'), (4, 'spectroroute')]\n"
     ]
    }
   ],
   "source": [
    "words = ['I', 'turned', 'off', 'the', 'spectroroute']\n",
    "tags = ['noun', 'verb', 'prep', 'det', 'noun']\n",
    "\n",
    "print(zip(words, tags))\n",
    "print(list(zip(words, tags)))\n",
    "print(list(enumerate(words)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Divide Up Training/Test Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = nltk.corpus.nps_chat.words()\n",
    "cut = int(0.9 * len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "9.0\n"
     ]
    }
   ],
   "source": [
    "training_data, test_data = text[:cut], text[cut:]\n",
    "\n",
    "# Verify that no data was lost\n",
    "print(text == training_data + test_data)\n",
    "\n",
    "# Verify ratio of sizes is correct\n",
    "print(len(training_data) / len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Combining Different Sequence Types</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Sorting: [(1, 'I'), (6, 'turned'), (3, 'off'), (3, 'the'), (12, 'spectroroute')]\n",
      "\n",
      "\n",
      "\n",
      "After Sorting: [(1, 'I'), (3, 'off'), (3, 'the'), (6, 'turned'), (12, 'spectroroute')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I off the turned spectroroute'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = 'I turned off the spectroroute'.split()\n",
    "wordlens = [(len(word), word) for word in words]\n",
    "\n",
    "print(\"Before Sorting: {}\".format(wordlens))\n",
    "wordlens.sort()\n",
    "print('\\n\\n')\n",
    "print(\"After Sorting: {}\".format(wordlens))\n",
    "\n",
    "' '.join(w for (_, w) in wordlens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Generator Expressions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object <genexpr> at 0x10b061af0>\n",
      "word\n"
     ]
    }
   ],
   "source": [
    "text = ('''\"When I use a word,\" Humpty Dumpty said in rather a scornful tone, \\\n",
    "\"it means just what I choose it to mean - neither more nor less.\"''')\n",
    "gen_tokens = (w.lower() for w in word_tokenize(text) if w.isalnum())\n",
    "print(gen_tokens)\n",
    "\n",
    "# Can call sequence function on tokens\n",
    "print(max(gen_tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fd = nltk.FreqDist(nltk.corpus.brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'of', 'and', 'to', 'a', 'in', 'that', 'is', 'was', 'for']\n",
      "  1    5.40%    the\n",
      "  2    8.51%     of\n",
      "  3   10.91%    and\n",
      "  4   13.13%     to\n",
      "  5   15.01%      a\n",
      "  6   16.69%     in\n",
      "  7   17.58%   that\n",
      "  8   18.44%     is\n",
      "  9   19.28%    was\n",
      " 10   20.04%    for\n",
      " 11   20.67%    The\n",
      " 12   21.27%   with\n",
      " 13   21.85%     it\n",
      " 14   22.43%     as\n",
      " 15   22.99%     he\n",
      " 16   23.55%    his\n",
      " 17   24.10%     on\n",
      " 18   24.65%     be\n",
      " 19   25.09%      I\n"
     ]
    }
   ],
   "source": [
    "cumulative = 0.0\n",
    "most_common_words = [word for (word, count) in fd.most_common()\n",
    "                     if word.isalnum()]\n",
    "print(most_common_words[:10])\n",
    "\n",
    "for rank, word in enumerate(most_common_words):\n",
    "    cumulative += fd.freq(word)\n",
    "    print(\"{:3} {:8.2%} {:>6}\".format(rank + 1, cumulative, word))\n",
    "    if cumulative > 0.25:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'dog', 'gave'), ('dog', 'gave', 'John'), ('gave', 'John', 'the'), ('John', 'the', 'newspaper')]\n",
      "\n",
      "\n",
      "\n",
      "('The', 'dog', 'gave')\n",
      "('dog', 'gave', 'John')\n",
      "('gave', 'John', 'the')\n",
      "('John', 'the', 'newspaper')\n"
     ]
    }
   ],
   "source": [
    "import _mypath\n",
    "import text_analysis as ta\n",
    "sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
    "n = 3\n",
    "\n",
    "# With my function\n",
    "my_ngrams = ta.extract_ngrams(n, sent)\n",
    "for ng in my_ngrams:\n",
    "    print(ng)\n",
    "\n",
    "print('\\n\\n')\n",
    "    \n",
    "# With nltk's\n",
    "n_grams = list(nltk.ngrams(sent, 3))\n",
    "for ng in n_grams:\n",
    "    print(ng, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)]\n",
      "[(2, 1), (2, 2), (2, 3), (2, 4), (2, 5)]\n",
      "[(3, 1), (3, 2), (3, 3), (3, 4), (3, 5)]\n",
      "[(4, 1), (4, 2), (4, 3), (4, 4), (4, 5)]\n",
      "[(5, 1), (5, 2), (5, 3), (5, 4), (5, 5)]\n",
      "[(6, 1), (6, 2), (6, 3), (6, 4), (6, 5)]\n",
      "[(7, 1), (7, 2), (7, 3), (7, 4), (7, 5)]\n",
      "[(8, 1), (8, 2), (8, 3), (8, 4), (8, 5)]\n",
      "[(9, 1), (9, 2), (9, 3), (9, 4), (9, 5)]\n"
     ]
    }
   ],
   "source": [
    "# Build a matrix\n",
    "m, n = 9, 5\n",
    "\n",
    "matrix = [[(i + 1, j + 1) for j in range(n)] for i in range(m)]\n",
    "for row in matrix:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>4.4 Functions</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Defensive Programming</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "det\n",
      "noun\n"
     ]
    }
   ],
   "source": [
    "def tag(word):\n",
    "    error = \"Argument to tag() must be a string\"\n",
    "    assert isinstance(word, str), error\n",
    "    if word in ['a', 'the', 'all']:\n",
    "        return 'det'\n",
    "    else:\n",
    "        return 'noun'\n",
    "\n",
    "print(tag(\"the\"))\n",
    "print(tag(\"cat\"))\n",
    "# This will throw an error\n",
    "# print(tag([\"a\", \"the\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', ',', '.', 'of', 'and', 'to', 'a', 'in', 'that', 'is']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "constitution = \"http://www.archives.gov/exhibits/charters/constitution_transcript.html\"\n",
    "\n",
    "def freq_words(url, n):\n",
    "    html = request.urlopen(url).read().decode(\"utf8\")\n",
    "    text = BeautifulSoup(html, \"lxml\").get_text()\n",
    "    freqdist = nltk.FreqDist(word.lower() for word in\n",
    "                             word_tokenize(text))\n",
    "    return [word for (word, _) in fd.most_common(n)]\n",
    "    \n",
    "freq_words(constitution, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>A Beautifully Documented Function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(reference, test):\n",
    "    \"\"\"\n",
    "    Calculate the fraction of test items that equal the corresponding reference items.\n",
    "\n",
    "    Given a list of reference values and a corresponding list of test values,\n",
    "    return the fraction of corresponding values that are equal.\n",
    "    In particular, return the fraction of indexes\n",
    "    {0<i<=len(test)} such that C{test[i] == reference[i]}.\n",
    "\n",
    "        >>> accuracy(['ADJ', 'N', 'V', 'N'], ['N', 'N', 'V', 'ADJ'])\n",
    "        0.5\n",
    "\n",
    "    :param reference: An ordered list of reference values\n",
    "    :type reference: list\n",
    "    :param test: A list of values to compare against the corresponding\n",
    "        reference values\n",
    "    :type test: list\n",
    "    :return: the accuracy score\n",
    "    :rtype: float\n",
    "    :raises ValueError: If reference and length do not have the same length\n",
    "    \"\"\"\n",
    "\n",
    "    if len(reference) != len(test):\n",
    "        raise ValueError(\"Lists must have the same length.\")\n",
    "    num_correct = 0\n",
    "    for x, y in zip(reference, test):\n",
    "        if x == y:\n",
    "            num_correct += 1\n",
    "    return float(num_correct) / len(reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>4.5 Doing More with Functions</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Functions as Arguments</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 4, 2, 3, 5, 1, 3, 3, 6, 4, 4, 4, 2, 10, 1]\n"
     ]
    }
   ],
   "source": [
    "sent = ['Take', 'care', 'of', 'the', 'sense', ',', 'and', 'the',\n",
    "        'sounds', 'will', 'take', 'care', 'of', 'themselves', '.']\n",
    "\n",
    "# ()'s ommitted when treating the function as an object\n",
    "def extract_property(prop):\n",
    "    return [prop(word) for word in sent]\n",
    "\n",
    "extract_property(len)\n",
    "\n",
    "# This same thing can be done with map\n",
    "mapped = map(len, sent)\n",
    "print(list(mapped))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Lambda</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e', 'e', 'f', 'e', 'e', ',', 'd', 'e', 's', 'l', 'e', 'e', 'f', 's', '.']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_property(lambda w: w[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', '.', 'Take', 'and', 'care', 'care', 'of', 'of', 'sense', 'sounds', 'take', 'the', 'the', 'themselves', 'will']\n",
      "['themselves', 'sounds', 'sense', 'Take', 'care', 'will', 'take', 'care', 'the', 'and', 'the', 'of', 'of', ',', '.']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(sent))\n",
    "\n",
    "# Sort by longest length to shortest length\n",
    "print(sorted(sent, key = lambda x: (- len(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Accumulative Functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_ss(substring, words):\n",
    "    result = []\n",
    "    for word in words:\n",
    "        if substring in word:\n",
    "            results.append(word)\n",
    "    return result\n",
    "\n",
    "def find_ss_gen(substring, words):\n",
    "    for word in words:\n",
    "        if substring in word:\n",
    "            yield word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grizzlies' fizzled Rizzuto huzzahs dazzler jazz Pezza Pezza Pezza embezzling embezzlement pizza jazz Ozzie nozzle drizzly puzzle puzzle dazzling Sizzling guzzle puzzles dazzling jazz jazz Jazz jazz Jazz jazz jazz Jazz jazz jazz jazz Jazz jazz dizzy jazz Jazz puzzler jazz jazzmen jazz jazz Jazz Jazz Jazz jazz Jazz jazz jazz jazz Jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz Jazz Jazz jazz jazz nozzles nozzle puzzle buzz puzzle blizzard blizzard sizzling puzzled puzzle puzzle muzzle muzzle muezzin blizzard Neo-Jazz jazz muzzle piazzas puzzles puzzles embezzle buzzed snazzy buzzes puzzled puzzled muzzle whizzing jazz Belshazzar Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie's Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie Lizzie blizzard blizzards blizzard blizzard fuzzy Lazzeri Piazza piazza palazzi Piazza Piazza Palazzo Palazzo Palazzo Piazza Piazza Palazzo palazzo palazzo Palazzo Palazzo Piazza piazza piazza piazza Piazza Piazza Palazzo palazzo Piazza piazza pizza Piazza Palazzo palazzo dazzling puzzling Wozzek dazzling dazzling buzzing Jazz jazz Jazz Jazz jazz jazz jazz jazz Jazz jazz jazz jazz Fuzzy Lizzy Lizzy jazz fuzzy puzzles puzzling puzzling dazzle puzzle dazzling puzzled jazz jazz jazz jazzy whizzed frazzled quizzical puzzling poetry-and-jazz poetry-and-jazz jazz jazz jazz jazz jazz jazz jazz Jazz jazz jazz jazz poetry-and-jazz jazz jazz jazz Dizzy jazz jazz jazz jazz jazz poetry-and-jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz jazz dazzled bedazzlement bedazzled Piazzo nozzles nozzles buzzing dazzles dizzy puzzling puzzling puzzling puzzle muzzle puzzled nozzle Pozzatti Pozzatti Pozzatti puzzled Pozzatti Pozzatti dazzling pizzicato Jazz jazz jazz jazz jazz nozzle grizzled fuzzy muzzle puzzled puzzle muzzle blizzard buzz dizzily drizzle drizzle drizzle sizzled puzzled puzzled puzzled fuzzed buzz buzz buzz buzz-buzz-buzz buzzes fuzzy frizzled drizzle drizzle drizzling drizzling fuzz jazz jazz fuzz puzzle puzzling Nozze mezzo puzzled puzzled dazzling muzzle muzzle muzzle buzzed whizzed sizzled palazzos puzzlement frizzling puzzled puzzled puzzled dazzling muzzles fuzzy jazz ex-jazz sizzle grizzly guzzled buzzing fuzz nuzzled Kizzie Kizzie Kizzie Kezziah Kizzie Kizzie Buzz's Buzz Buzz Buzz Buzz Buzz Buzz Buzz Buzz dizzy piazza buzzing Puzzled dizziness dazzled Piazza Carrozza fuzzy dizzy buzzing buzzing puzzled puzzling puzzled puzzled Quizzical pizza "
     ]
    }
   ],
   "source": [
    "words = nltk.corpus.brown.words()\n",
    "for item in find_ss_gen(\"zz\", words):\n",
    "    print(item, end=\" \")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['police', 'fish', 'buffalo'],\n",
       " ['fish', 'police', 'buffalo'],\n",
       " ['fish', 'buffalo', 'police'],\n",
       " ['police', 'buffalo', 'fish'],\n",
       " ['buffalo', 'police', 'fish'],\n",
       " ['buffalo', 'fish', 'police']]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def permutations(seq):\n",
    "    if len(seq) <= 1:\n",
    "        yield seq\n",
    "    else:\n",
    "        for perm in permutations(seq[1:]):\n",
    "            for i in range(len(perm) + 1):\n",
    "                yield perm[:i] + seq[0:1] + perm[i:]\n",
    "                \n",
    "list(permutations([\"police\", \"fish\", \"buffalo\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Named Arguments</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JigglesJigglesJigglesJigglesJigglesJigglesJigglesJigglesJigglesJiggles'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def repeat(msg=\"<empty>\", num=1):\n",
    "    return msg * num\n",
    "\n",
    "repeat(num=3)\n",
    "repeat(msg=\"Jiggles\", num=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args:  (1, 'African swallow')\n",
      "kwargs:  {'monty': 'python'}\n"
     ]
    }
   ],
   "source": [
    "def generic(*args, **kwargs):\n",
    "    print(\"args: \", args)\n",
    "    print(\"kwargs: \", kwargs)\n",
    "    \n",
    "generic(1, \"African swallow\", monty=\"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Star</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('four', 'three', 'two'),\n",
       " ('calling', 'french', 'turtle'),\n",
       " ('birds', 'hens', 'doves')]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song = [[\"four\", \"calling\", \"birds\"],\n",
    "        [\"three\", \"french\", \"hens\"],\n",
    "        [\"two\", \"turtle\", \"doves\"]]\n",
    "\n",
    "list(zip(song[0], song[1], song[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('four', 'three', 'two'),\n",
       " ('calling', 'french', 'turtle'),\n",
       " ('birds', 'hens', 'doves')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(*song))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(val1=\"a\", val2=\"b\"):\n",
    "    print(val1, val2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
