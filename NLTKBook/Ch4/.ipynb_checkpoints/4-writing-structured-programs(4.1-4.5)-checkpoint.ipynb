{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>4.1 Back to the Basics</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Shallow Copy</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: [[1, 2, 3, -7], [4, 5, 6], [7, 8, 9]]\n",
      "\n",
      "B: [[1, 2, 3, -7], [4, 5, 6], [7, 8, 9]]\n"
     ]
    }
   ],
   "source": [
    "i = [1, 2, 3]\n",
    "j = [4, 5, 6]\n",
    "k = [7, 8, 9]\n",
    "\n",
    "a = [i, j, k]\n",
    "# Copy the object references from a\n",
    "b = a[:]\n",
    "b[0].append(-7)\n",
    "\n",
    "print(\"A: {}\\n\\nB: {}\".format(a, b,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Deep Copy</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: [[1, 2, 3, -7], [4, 5, 6], [7, 8, 9]]\n",
      "\n",
      "B: [[1, 2, 3, -7], [4, 5, 6], [7, 8, 9]]\n",
      "\n",
      "C: [[1, 2, 3, -7, -999], [4, 5, 6], [7, 8, 9]]\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy as dc\n",
    "\n",
    "c = dc(a)\n",
    "c[0].append(-999)\n",
    "print(\"A: {}\\n\\nB: {}\\n\\nC: {}\".format(a, b, c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Equality</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Python'], ['Python'], ['Python'], ['Python'], ['Python']]\n",
      "KITTY CAT\n",
      "PUPPY DOG\n",
      "4533307336\n",
      "4533307336\n",
      "4533307336\n",
      "4533307336\n",
      "4533307336\n",
      "\n",
      "\n",
      "round 2\n",
      "[['Python'], ['Python'], ['Python'], ['Python'], ['Python']]\n",
      "KITTY CAT\n",
      "4531049544\n",
      "4533307336\n",
      "4533307336\n",
      "4533307336\n",
      "4533307336\n"
     ]
    }
   ],
   "source": [
    "size = 5\n",
    "python = [\"Python\"]\n",
    "snake_nest = [python] * size\n",
    "\n",
    "def test(nest):\n",
    "    print(nest)\n",
    "    # ==: same values\n",
    "    if nest[0] == nest[1] == nest[2] == nest[3] == nest[4]:\n",
    "        print(\"KITTY CAT\")\n",
    "    # is: same identity\n",
    "    if nest[0] is nest[1] is nest[2] is nest[3] is nest[4]:\n",
    "        print(\"PUPPY DOG\")\n",
    "\n",
    "def check_ids(nest):\n",
    "    for snake in nest:\n",
    "        print(id(snake))\n",
    "            \n",
    "test(snake_nest)\n",
    "check_ids(snake_nest)\n",
    "\n",
    "print(\"\\n\\nround 2\")\n",
    "import random\n",
    "pos = random.choice(range(size))\n",
    "snake_nest[pos] = [\"Python\"]\n",
    "\n",
    "test(snake_nest)\n",
    "check_ids(snake_nest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "sent = ['No', 'good', 'fish', 'goes', 'anywhere', 'without', 'a', 'porpoise', '.']\n",
    "print(all(len(w) > 4 for w in sent))\n",
    "\n",
    "print(any(len(w) > 4 for w in sent))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>4.2 Sequences</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('David', 234, ['Chocolate', 'Racecars'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faves = [\"Chocolate\", \"Racecars\"]\n",
    "tup = \"David\", 234, faves\n",
    "tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[',', '.', 'Red', 'lorry', 'red', 'yellow']\n",
      "Red: 1;  lorry: 4;  ,: 3;  yellow: 2;  red: 1;  .: 1;  "
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "raw = 'Red lorry, yellow lorry, red lorry, yellow lorry.'\n",
    "text = word_tokenize(raw)\n",
    "fdist = nltk.FreqDist(text)\n",
    "print(sorted(fdist))\n",
    "for key in fdist:\n",
    "    print(\"{}: {}; \".format(key, fdist[key]), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'turned', 'the', 'spectroroute', 'off']\n"
     ]
    }
   ],
   "source": [
    "words = ['I', 'turned', 'off', 'the', 'spectroroute']\n",
    "words[2], words[3], words[4] = words[3], words[4], words[2]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zip object at 0x10c955e48>\n",
      "[('I', 'noun'), ('turned', 'verb'), ('off', 'prep'), ('the', 'det'), ('spectroroute', 'noun')]\n",
      "[(0, 'I'), (1, 'turned'), (2, 'off'), (3, 'the'), (4, 'spectroroute')]\n"
     ]
    }
   ],
   "source": [
    "words = ['I', 'turned', 'off', 'the', 'spectroroute']\n",
    "tags = ['noun', 'verb', 'prep', 'det', 'noun']\n",
    "\n",
    "print(zip(words, tags))\n",
    "print(list(zip(words, tags)))\n",
    "print(list(enumerate(words)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Divide Up Training/Test Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = nltk.corpus.nps_chat.words()\n",
    "cut = int(0.9 * len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "9.0\n"
     ]
    }
   ],
   "source": [
    "training_data, test_data = text[:cut], text[cut:]\n",
    "\n",
    "# Verify that no data was lost\n",
    "print(text == training_data + test_data)\n",
    "\n",
    "# Verify ratio of sizes is correct\n",
    "print(len(training_data) / len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Combining Different Sequence Types</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Sorting: [(1, 'I'), (6, 'turned'), (3, 'off'), (3, 'the'), (12, 'spectroroute')]\n",
      "\n",
      "\n",
      "\n",
      "After Sorting: [(1, 'I'), (3, 'off'), (3, 'the'), (6, 'turned'), (12, 'spectroroute')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I off the turned spectroroute'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = 'I turned off the spectroroute'.split()\n",
    "wordlens = [(len(word), word) for word in words]\n",
    "\n",
    "print(\"Before Sorting: {}\".format(wordlens))\n",
    "wordlens.sort()\n",
    "print('\\n\\n')\n",
    "print(\"After Sorting: {}\".format(wordlens))\n",
    "\n",
    "' '.join(w for (_, w) in wordlens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Generator Expressions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object <genexpr> at 0x112529e08>\n",
      "word\n"
     ]
    }
   ],
   "source": [
    "text = ('''\"When I use a word,\" Humpty Dumpty said in rather a scornful tone, \\\n",
    "\"it means just what I choose it to mean - neither more nor less.\"''')\n",
    "gen_tokens = (w.lower() for w in word_tokenize(text) if w.isalnum())\n",
    "print(gen_tokens)\n",
    "\n",
    "# Can call sequence function on tokens\n",
    "print(max(gen_tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fd = nltk.FreqDist(nltk.corpus.brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'of', 'and', 'to', 'a', 'in', 'that', 'is', 'was', 'for']\n",
      "  1    5.40%    the\n",
      "  2    8.51%     of\n",
      "  3   10.91%    and\n",
      "  4   13.13%     to\n",
      "  5   15.01%      a\n",
      "  6   16.69%     in\n",
      "  7   17.58%   that\n",
      "  8   18.44%     is\n",
      "  9   19.28%    was\n",
      " 10   20.04%    for\n",
      " 11   20.67%    The\n",
      " 12   21.27%   with\n",
      " 13   21.85%     it\n",
      " 14   22.43%     as\n",
      " 15   22.99%     he\n",
      " 16   23.55%    his\n",
      " 17   24.10%     on\n",
      " 18   24.65%     be\n",
      " 19   25.09%      I\n"
     ]
    }
   ],
   "source": [
    "cumulative = 0.0\n",
    "most_common_words = [word for (word, count) in fd.most_common()\n",
    "                     if word.isalnum()]\n",
    "print(most_common_words[:10])\n",
    "\n",
    "for rank, word in enumerate(most_common_words):\n",
    "    cumulative += fd.freq(word)\n",
    "    print(\"{:3} {:8.2%} {:>6}\".format(rank + 1, cumulative, word))\n",
    "    if cumulative > 0.25:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'dog', 'gave'), ('dog', 'gave', 'John'), ('gave', 'John', 'the'), ('John', 'the', 'newspaper')]\n",
      "\n",
      "\n",
      "\n",
      "('The', 'dog', 'gave')\n",
      "('dog', 'gave', 'John')\n",
      "('gave', 'John', 'the')\n",
      "('John', 'the', 'newspaper')\n"
     ]
    }
   ],
   "source": [
    "import _mypath\n",
    "import text_analysis as ta\n",
    "sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
    "n = 3\n",
    "\n",
    "# With my function\n",
    "my_ngrams = ta.extract_ngrams(n, sent)\n",
    "for ng in my_ngrams:\n",
    "    print(ng)\n",
    "\n",
    "print('\\n\\n')\n",
    "    \n",
    "# With nltk's\n",
    "n_grams = list(nltk.ngrams(sent, 3))\n",
    "for ng in n_grams:\n",
    "    print(ng, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)]\n",
      "[(2, 1), (2, 2), (2, 3), (2, 4), (2, 5)]\n",
      "[(3, 1), (3, 2), (3, 3), (3, 4), (3, 5)]\n",
      "[(4, 1), (4, 2), (4, 3), (4, 4), (4, 5)]\n",
      "[(5, 1), (5, 2), (5, 3), (5, 4), (5, 5)]\n",
      "[(6, 1), (6, 2), (6, 3), (6, 4), (6, 5)]\n",
      "[(7, 1), (7, 2), (7, 3), (7, 4), (7, 5)]\n",
      "[(8, 1), (8, 2), (8, 3), (8, 4), (8, 5)]\n",
      "[(9, 1), (9, 2), (9, 3), (9, 4), (9, 5)]\n"
     ]
    }
   ],
   "source": [
    "# Build a matrix\n",
    "m, n = 9, 5\n",
    "\n",
    "matrix = [[(i + 1, j + 1) for j in range(n)] for i in range(m)]\n",
    "for row in matrix:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>4.4 Functions</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Defensive Programming</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "det\n",
      "noun\n"
     ]
    }
   ],
   "source": [
    "def tag(word):\n",
    "    error = \"Argument to tag() must be a string\"\n",
    "    assert isinstance(word, str), error\n",
    "    if word in ['a', 'the', 'all']:\n",
    "        return 'det'\n",
    "    else:\n",
    "        return 'noun'\n",
    "\n",
    "print(tag(\"the\"))\n",
    "print(tag(\"cat\"))\n",
    "# This will throw an error\n",
    "# print(tag([\"a\", \"the\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', ',', '.', 'of', 'and', 'to', 'a', 'in', 'that', 'is']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib import request\n",
    "from bs4 import BeautifulSoup\n",
    "constitution = \"http://www.archives.gov/exhibits/charters/constitution_transcript.html\"\n",
    "\n",
    "def freq_words(url, n):\n",
    "    html = request.urlopen(url).read().decode(\"utf8\")\n",
    "    text = BeautifulSoup(html, \"lxml\").get_text()\n",
    "    freqdist = nltk.FreqDist(word.lower() for word in\n",
    "                             word_tokenize(text))\n",
    "    return [word for (word, _) in fd.most_common(n)]\n",
    "    \n",
    "freq_words(constitution, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>A Beautifully Documented Function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(reference, test):\n",
    "    \"\"\"\n",
    "    Calculate the fraction of test items that equal the corresponding reference items.\n",
    "\n",
    "    Given a list of reference values and a corresponding list of test values,\n",
    "    return the fraction of corresponding values that are equal.\n",
    "    In particular, return the fraction of indexes\n",
    "    {0<i<=len(test)} such that C{test[i] == reference[i]}.\n",
    "\n",
    "        >>> accuracy(['ADJ', 'N', 'V', 'N'], ['N', 'N', 'V', 'ADJ'])\n",
    "        0.5\n",
    "\n",
    "    :param reference: An ordered list of reference values\n",
    "    :type reference: list\n",
    "    :param test: A list of values to compare against the corresponding\n",
    "        reference values\n",
    "    :type test: list\n",
    "    :return: the accuracy score\n",
    "    :rtype: float\n",
    "    :raises ValueError: If reference and length do not have the same length\n",
    "    \"\"\"\n",
    "\n",
    "    if len(reference) != len(test):\n",
    "        raise ValueError(\"Lists must have the same length.\")\n",
    "    num_correct = 0\n",
    "    for x, y in zip(reference, test):\n",
    "        if x == y:\n",
    "            num_correct += 1\n",
    "    return float(num_correct) / len(reference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
