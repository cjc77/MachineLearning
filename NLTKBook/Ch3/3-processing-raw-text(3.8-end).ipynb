{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>3.8 Segmentation</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Sentence Segmentation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "brown = nltk.corpus.brown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.250994070456922\n"
     ]
    }
   ],
   "source": [
    "avg_sent_len = len(brown.words()) / len(brown.sents())\n",
    "print(avg_sent_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"Nonsense!\"',\n",
      " 'said Gregory, who was very rational when anyone else\\nattempted paradox.',\n",
      " '\"Why do all the clerks and navvies in the\\n'\n",
      " 'railway trains look so sad and tired, so very sad and tired?',\n",
      " 'I will\\ntell you.',\n",
      " 'It is because they know that the train is going right.',\n",
      " 'It\\n'\n",
      " 'is because they know that whatever place they have taken a ticket\\n'\n",
      " 'for that place they will reach.',\n",
      " 'It is because after they have\\n'\n",
      " 'passed Sloane Square they know that the next station must be\\n'\n",
      " 'Victoria, and nothing but Victoria.',\n",
      " 'Oh, their wild rapture!',\n",
      " 'oh,\\n'\n",
      " 'their eyes like stars and their souls again in Eden, if the next\\n'\n",
      " 'station were unaccountably Baker Street!\"',\n",
      " '\"It is you who are unpoetical,\" replied the poet Syme.']\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "text = nltk.corpus.gutenberg.raw(\"chesterton-thursday.txt\")\n",
    "sents = nltk.sent_tokenize(text)\n",
    "pprint.pprint(sents[79:89])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Word Segmentation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import _mypath\n",
    "import language_mod as lm\n",
    "\n",
    "text = \"doyouseethekittyseethedoggydoyoulikethekittylikethedoggy\"\n",
    "\n",
    "# Segment by clusters of words\n",
    "seg1 = \"0000000000000001000000000010000000000000000100000000000\"\n",
    "\n",
    "# Segment by single words\n",
    "seg2 = \"0100100100100001001001000010100100010010000100010010000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "\n",
      "['do', 'you', 'see', 'the', 'kitty', 'see', 'the', 'doggy', 'do', 'you', 'like', 'the', 'kitty', 'like', 'the', 'doggy']\n"
     ]
    }
   ],
   "source": [
    "# Segment the text\n",
    "clust = lm.segment(text, seg1)\n",
    "words = lm.segment(text, seg2)\n",
    "\n",
    "print(clust, words, sep=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Images/brent.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['doyou', 'see', 'thekitt', 'y', 'see', 'thedogg', 'y', 'doyou', 'like', 'thekitt', 'y', 'like', 'thedogg', 'y']\n",
      "47\n",
      "48\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "seg3 = \"0000100100000011001000000110000100010000001100010000001\"\n",
    "print(lm.segment(text, seg3))\n",
    "print(lm.evaluate(text, seg3))\n",
    "print(lm.evaluate(text, seg2))\n",
    "print(lm.evaluate(text, seg1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "62 ['doyousee', 'theki', 'ttyseet', 'hedoggy', 'doyoulikethekit', 'tyliket', 'hedoggy']\n",
      "62 ['doyousee', 'theki', 'ttyseet', 'hedoggy', 'doyoulikethekit', 'tyliket', 'hedoggy']\n",
      "62 ['doyousee', 'theki', 'ttyseet', 'hedoggy', 'doyoulikethekit', 'tyliket', 'hedoggy']\n",
      "60 ['doyouseethekittyseet', 'hedoggy', 'do', 'youlikethek', 'ittyliket', 'hedoggy']\n",
      "56 ['doyou', 'seethekittys', 'eet', 'hedoggy', 'doyou', 'liket', 'hek', 'itty', 'liket', 'hedoggy']\n",
      "53 ['doyou', 'seethek', 'itty', 'seet', 'hedoggy', 'doyou', 'liket', 'hek', 'itty', 'liket', 'hedoggy']\n",
      "51 ['doyou', 'seet', 'hekitty', 'seet', 'hedoggy', 'doyou', 'like', 't', 'hekitty', 'liket', 'hedoggy']\n",
      "51 ['doyou', 'seet', 'hekitty', 'seet', 'hedoggy', 'doyou', 'like', 't', 'hekitty', 'liket', 'hedoggy']\n",
      "43 ['doyou', 'seet', 'hekitty', 'seet', 'hedoggy', 'doyou', 'liket', 'hekitty', 'liket', 'hedoggy']\n",
      "43 ['doyou', 'seet', 'hekitty', 'seet', 'hedoggy', 'doyou', 'liket', 'hekitty', 'liket', 'hedoggy']\n",
      "43 ['doyou', 'seet', 'hekitty', 'seet', 'hedoggy', 'doyou', 'liket', 'hekitty', 'liket', 'hedoggy']\n",
      "43 ['doyou', 'seet', 'hekitty', 'seet', 'hedoggy', 'doyou', 'liket', 'hekitty', 'liket', 'hedoggy']\n",
      "43 ['doyou', 'seet', 'hekitty', 'seet', 'hedoggy', 'doyou', 'liket', 'hekitty', 'liket', 'hedoggy']\n",
      "43 ['doyou', 'seet', 'hekitty', 'seet', 'hedoggy', 'doyou', 'liket', 'hekitty', 'liket', 'hedoggy']\n",
      "43 ['doyou', 'seet', 'hekitty', 'seet', 'hedoggy', 'doyou', 'liket', 'hekitty', 'liket', 'hedoggy']\n",
      "43 ['doyou', 'seet', 'hekitty', 'seet', 'hedoggy', 'doyou', 'liket', 'hekitty', 'liket', 'hedoggy']\n",
      "43 ['doyou', 'seet', 'hekitty', 'seet', 'hedoggy', 'doyou', 'liket', 'hekitty', 'liket', 'hedoggy']\n",
      "43 ['doyou', 'seet', 'hekitty', 'seet', 'hedoggy', 'doyou', 'liket', 'hekitty', 'liket', 'hedoggy']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0000100010000001000100000010000100001000000100001000000'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.anneal(text, seg1, 5000, 1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>3.9 Formatting: From Lists to Strings</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>From Lists to Strings</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We called him Tortoise because he taught us .\n",
      "We;called;him;Tortoise;because;he;taught;us;.\n",
      "WecalledhimTortoisebecausehetaughtus.\n"
     ]
    }
   ],
   "source": [
    "silly = ['We', 'called', 'him', 'Tortoise', 'because', 'he', 'taught', 'us', '.']\n",
    "\n",
    "silly_sp = ' '.join(silly)\n",
    "silly_sc = ';'.join(silly)\n",
    "silly_nsp = ''.join(silly)\n",
    "\n",
    "print(silly_sp)\n",
    "print(silly_sc)\n",
    "print(silly_nsp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Strings and Formats</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "Hello\n",
      "world.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = \"cat\"\n",
    "sentence = \"\"\"Hello\n",
    "world.\"\"\"\n",
    "print(word)\n",
    "print(sentence)\n",
    "word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello\\nworld.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat -> 3; dog -> 4; snake -> 1; "
     ]
    }
   ],
   "source": [
    "fdist = nltk.FreqDist(['dog', 'cat', 'dog', 'cat', 'dog',\n",
    "                       'snake', 'dog', 'cat'])\n",
    "for word in sorted(fdist):\n",
    "    print(word, '->', fdist[word], end='; ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>String Formatting</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat -> 3; dog -> 4; snake -> 1; "
     ]
    }
   ],
   "source": [
    "# \"{} \".format(): called a format string\n",
    "for word in sorted(fdist):\n",
    "    print(\"{} -> {};\".format(word, fdist[word]), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Carson is a cool guy'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extra args are ignored\n",
    "\"{} is a cool guy\".format(\"Carson\", \"Pandas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from B to A'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Swap ordering\n",
    "\"from {1} to {0}\".format(\"A\", \"B\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lee wants a sandwich right now\n",
      "Lee wants a bagle right now\n",
      "Lee wants a eagle right now\n"
     ]
    }
   ],
   "source": [
    "# Loopy example\n",
    "template = \"Lee wants a {} right now\"\n",
    "menu = [\"sandwich\", \"bagle\", \"eagle\"]\n",
    "for snack in menu:\n",
    "    print(template.format(snack))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     7\n",
      "7     \n"
     ]
    }
   ],
   "source": [
    "# Numbers are right justified by default\n",
    "\n",
    "# Right Justified\n",
    "print(\"{:6}\".format(7))\n",
    "\n",
    "# Left Justified\n",
    "print(\"{:<6}\".format(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog   \n"
     ]
    }
   ],
   "source": [
    "print(\"{:6}\".format(\"dog\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dog\n"
     ]
    }
   ],
   "source": [
    "print(\"{:>6}\".format(\"dog\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1416\n"
     ]
    }
   ],
   "source": [
    "# Specify Precision\n",
    "import math\n",
    "print(\"{:.4f}\".format(math.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'accuracy for 9375 words: 34.1867%'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Smart representation of percentages\n",
    "count, total = 3205, 9375\n",
    "\"accuracy for {} words: {:.4%}\".format(total, count / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "from nltk import ConditionalFreqDist as cfd\n",
    "import text_analysis as ta\n",
    "\n",
    "brown_cfd = cfd(\n",
    "                (genre, word)\n",
    "                for genre in brown.categories()\n",
    "                for word in brown.words(categories=genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n"
     ]
    }
   ],
   "source": [
    "genres = brown.categories()\n",
    "print(genres)\n",
    "modals = [\"can\", \"could\", \"may\", \"might\", \"must\", \"will\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category            can  could    may  might   must   will \n",
      "adventure            46    151      5     58     27     50 \n",
      "belles_lettres      246    213    207    113    170    236 \n",
      "editorial           121     56     74     39     53    233 \n",
      "fiction              37    166      8     44     55     52 \n",
      "government          117     38    153     13    102    244 \n",
      "hobbies             268     58    131     22     83    264 \n",
      "humor                16     30      8      8      9     13 \n",
      "learned             365    159    324    128    202    340 \n",
      "lore                170    141    165     49     96    175 \n",
      "mystery              42    141     13     57     30     20 \n",
      "news                 93     86     66     38     50    389 \n",
      "religion             82     59     78     12     54     71 \n",
      "reviews              45     40     45     26     19     58 \n",
      "romance              74    193     11     51     45     43 \n",
      "science_fiction      16     49      4     12      8     16 \n"
     ]
    }
   ],
   "source": [
    "ta.tabulate(brown_cfd, modals, genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adventure           9\n",
      "belles_lettres      14\n",
      "editorial           9\n",
      "fiction             7\n",
      "government          10\n",
      "hobbies             7\n",
      "humor               5\n",
      "learned             7\n",
      "lore                4\n",
      "mystery             7\n",
      "news                4\n",
      "religion            8\n",
      "reviews             7\n",
      "romance             7\n",
      "science_fiction     15\n"
     ]
    }
   ],
   "source": [
    "# customize column width\n",
    "m_width = max(len(g) for g in genres) + 4\n",
    "for genre in genres:\n",
    "    print(\"{:{max_width}} {}\".format(genre, len(genre), max_width=m_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Writing Results to a File</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2789\n"
     ]
    }
   ],
   "source": [
    "output_file = open(\"output.txt\", \"w\")\n",
    "words = set(nltk.corpus.genesis.words(\"english-kjv.txt\"))\n",
    "for word in sorted(words):\n",
    "    if word.isalnum():\n",
    "        print(word, file=output_file)\n",
    "\n",
    "# This will put the number at the end of the file\n",
    "        \n",
    "# Numeric data must be converted to a string before it\n",
    "# can be written out to a file\n",
    "print(len(words))\n",
    "print(str(len(words)), file=output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Text Wrapping</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After (5) all (3) is (2) said (4) and (3) done (4) , (1) more (4) is (2) said (4) than (4) done (4) . (1) "
     ]
    }
   ],
   "source": [
    "saying = ['After', 'all', 'is', 'said', 'and', 'done', ',',\n",
    "          'more', 'is', 'said', 'than', 'done', '.']\n",
    "for word in saying:\n",
    "    print(word, \"(\" + str(len(word)) + \")\", end=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After (5), all (3), is (2), said (4), and (3), done (4), , (1), more\n",
      "(4), is (2), said (4), than (4), done (4), . (1),\n"
     ]
    }
   ],
   "source": [
    "from textwrap import fill\n",
    "\n",
    "format = \"%s (%d),\"\n",
    "pieces = [format % (word, len(word)) for word in saying]\n",
    "output = ' '.join(pieces)\n",
    "wrapped = fill(output)\n",
    "print(wrapped)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
