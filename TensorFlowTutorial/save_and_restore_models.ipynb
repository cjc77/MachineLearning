{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carso\\Anaconda3\\envs\\tflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "y_train = y_train[:1000]\n",
    "y_test = y_test[:1000]\n",
    "\n",
    "X_train = X_train[:1000].reshape(-1, 28 * 28) / 255.0\n",
    "X_test = X_test[:1000].reshape(-1, 28 * 28) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(784,)),\n",
    "        keras.layers.Dropout(0.2),\n",
    "        keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "model1 = create_model()\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save checkpoints during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint callback usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 469us/step - loss: 1.1295 - acc: 0.6900 - val_loss: 0.7059 - val_acc: 0.8070\n",
      "\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 276us/step - loss: 0.4106 - acc: 0.8860 - val_loss: 0.5366 - val_acc: 0.8290\n",
      "\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 265us/step - loss: 0.2879 - acc: 0.9270 - val_loss: 0.4784 - val_acc: 0.8470\n",
      "\n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 263us/step - loss: 0.2029 - acc: 0.9500 - val_loss: 0.4541 - val_acc: 0.8480\n",
      "\n",
      "Epoch 00004: saving model to training_1/cp.ckpt\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 238us/step - loss: 0.1556 - acc: 0.9650 - val_loss: 0.4448 - val_acc: 0.8530\n",
      "\n",
      "Epoch 00005: saving model to training_1/cp.ckpt\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 239us/step - loss: 0.1194 - acc: 0.9770 - val_loss: 0.4265 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00006: saving model to training_1/cp.ckpt\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 219us/step - loss: 0.0833 - acc: 0.9900 - val_loss: 0.4090 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00007: saving model to training_1/cp.ckpt\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 224us/step - loss: 0.0752 - acc: 0.9900 - val_loss: 0.4209 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00008: saving model to training_1/cp.ckpt\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 222us/step - loss: 0.0493 - acc: 0.9970 - val_loss: 0.4136 - val_acc: 0.8580\n",
      "\n",
      "Epoch 00009: saving model to training_1/cp.ckpt\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 228us/step - loss: 0.0383 - acc: 1.0000 - val_loss: 0.4090 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00010: saving model to training_1/cp.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25184ba7b00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, save_weights_only=True, verbose=1\n",
    ")\n",
    "\n",
    "model1.fit(\n",
    "    X_train, y_train, epochs=10,\n",
    "    validation_data = (X_test, y_test),\n",
    "    callbacks=[cp_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new, untrained model\n",
    "Model must have the same architecture as the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 111us/step\n",
      "Untrained model, acc: 10.30\n"
     ]
    }
   ],
   "source": [
    "model2 = create_model()\n",
    "\n",
    "# Accuracy should be somewhere around 10%\n",
    "loss, acc = model2.evaluate(X_test, y_test)\n",
    "print(\"Untrained model, acc: {:.2f}\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in weights from checkpoint and re-evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 37us/step\n",
      "Restored model, acc: 86.80\n"
     ]
    }
   ],
   "source": [
    "model2.load_weights(checkpoint_path)\n",
    "loss, acc = model2.evaluate(X_test, y_test)\n",
    "print(\"Restored model, acc: {:.2f}\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint callback options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: saving model to training_2/cp-0005.ckpt\n",
      "\n",
      "Epoch 00010: saving model to training_2/cp-0010.ckpt\n",
      "\n",
      "Epoch 00015: saving model to training_2/cp-0015.ckpt\n",
      "\n",
      "Epoch 00020: saving model to training_2/cp-0020.ckpt\n",
      "\n",
      "Epoch 00025: saving model to training_2/cp-0025.ckpt\n",
      "\n",
      "Epoch 00030: saving model to training_2/cp-0030.ckpt\n",
      "\n",
      "Epoch 00035: saving model to training_2/cp-0035.ckpt\n",
      "\n",
      "Epoch 00040: saving model to training_2/cp-0040.ckpt\n",
      "\n",
      "Epoch 00045: saving model to training_2/cp-0045.ckpt\n",
      "\n",
      "Epoch 00050: saving model to training_2/cp-0050.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x251899575c0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# include epoch in file name\n",
    "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Note: the default tensofrlow format will only save the 5 most recent checkpoints\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, verbose=1, save_weights_only=True,\n",
    "    # save weights every 5 epochs\n",
    "    period=5\n",
    ")\n",
    "\n",
    "model3 = create_model()\n",
    "model3.fit(\n",
    "    X_train, y_train, epochs=50, callbacks=[cp_callback],\n",
    "    validation_data = (X_test, y_test), verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training_2\\\\cp-0050.ckpt'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 88us/step\n",
      "Restored model, acc: 87.50\n"
     ]
    }
   ],
   "source": [
    "model4 = create_model()\n",
    "model4.load_weights(latest)\n",
    "loss, acc = model4.evaluate(X_test, y_test)\n",
    "print(\"Restored model, acc: {:.2f}\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "model4.save_weights(\"./checkpoints/my_checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 98us/step\n",
      "Restored model, acc: 87.50\n"
     ]
    }
   ],
   "source": [
    "# Restore the weights\n",
    "model5 = create_model()\n",
    "model5.load_weights(\"./checkpoints/my_checkpoint\")\n",
    "loss, acc = model5.evaluate(X_test, y_test)\n",
    "print(\"Restored model, acc: {:.2f}\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the entire model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As an HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 471us/step - loss: 1.1505 - acc: 0.6710\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 187us/step - loss: 0.4194 - acc: 0.8820\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 187us/step - loss: 0.2765 - acc: 0.9360\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 200us/step - loss: 0.2099 - acc: 0.9510\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 196us/step - loss: 0.1482 - acc: 0.9690\n"
     ]
    }
   ],
   "source": [
    "model6 = create_model()\n",
    "\n",
    "# Need to use a keras optimizer to restore optimizer state\n",
    "model6.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model6.fit(X_train, y_train, epochs=5)\n",
    "\n",
    "# Save the entire model to an HDF5 file\n",
    "model6.save(\"model6.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recreate model from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1000/1000 [==============================] - 0s 141us/step\n",
      "Restored model, acc: 84.90\n"
     ]
    }
   ],
   "source": [
    "model6a = keras.models.load_model(\"model6.h5\")\n",
    "model6a.summary()\n",
    "loss, acc = model6a.evaluate(X_test, y_test)\n",
    "print(\"Restored model, acc: {:.2f}\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As a **saved_model**\n",
    "*Doesn't work on my current version (1.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 1s 642us/step - loss: 1.2041 - acc: 0.6440\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 187us/step - loss: 0.4329 - acc: 0.8790\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 189us/step - loss: 0.2824 - acc: 0.9260\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 190us/step - loss: 0.2035 - acc: 0.9550\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 192us/step - loss: 0.1631 - acc: 0.9610\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.contrib.saved_model' has no attribute 'save_keras_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-75f737d74842>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Create a saved model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m saved_model_path = tf.contrib.saved_model.save_keras_model(\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mmodel7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;34m\"./saved_models\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.contrib.saved_model' has no attribute 'save_keras_model'"
     ]
    }
   ],
   "source": [
    "# model7 = create_model()\n",
    "# model7.fit(X_train, y_train, epochs=5)\n",
    "\n",
    "# # Create a saved model\n",
    "# saved_model_path = tf.contrib.saved_model.save_keras_model(\n",
    "#     model7,\n",
    "#     \"./saved_models\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
